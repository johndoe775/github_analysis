def llm_fx(state: State) -> dict:
            key = state["option"]
            input_variables = list(self.data[key]["inputs"].keys())
            template = self.data[key]["prompt"].format(
                resume=self.resume,
                job_description=self.job_description,
                personal_info=self.personal_info,
            )
            prompt_template = PromptTemplate(
                input_variables=input_variables, template=template
            )
            chain = prompt_template | LLM().llm
            response = chain.invoke(self.data[key]["inputs"]).content
            state["messages"].append(AIMessage(content=response))
            return state