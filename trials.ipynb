{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import List, TypedDict, Annotated\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "\"\"\"\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.graph import Graph, Node, StartNode, StopNode\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\"\"\"\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.environ[\"groq\"]\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0468482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c26187d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Taj Mahal is located in Agra, a city in the Indian state of Uttar Pradesh. It is situated on the southern bank of the Yamuna River, approximately 230 kilometers (143 miles) south of New Delhi, the capital city of India.\\n\\nThe exact address of the Taj Mahal is:\\n\\nTaj Mahal, Dharmapuri, Forest Colony, Tajganj, Agra, Uttar Pradesh 282001, India\\n\\nIt is one of the most famous and iconic monuments in the world, and a popular tourist destination, attracting millions of visitors each year.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"where is taj mahal?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "05468958",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume,personal_info=\"\",\"\"\"Strategic and results-driven talent acquisition leader with a proven track record in recruiting and talent management across diverse industries. I specialize in designing and executing scalable recruitment strategies that align with organizational goals and elevate the candidate experience.\n",
    "\n",
    "With a deep understanding of data-driven hiring, I leverage analytics to streamline processes, enhance team performance, and drive informed decision-making. I’m not just focused on filling roles—I build and lead high-performing recruitment teams capable of managing high-volume, cross-functional hiring with precision and efficiency.\n",
    "\n",
    "My approach has consistently improved hiring outcomes, aligning recruitment operations with business objectives while ensuring an exceptional stakeholder experience. Backed by a strong foundation in Customer Relationship Management and Human Resources, I am passionate about delivering excellence in every aspect of talent acquisition.\"\"\"\n",
    "with open('data/job_description.txt', 'r') as file:\n",
    "    job_description=file.read()\n",
    "loader = PyPDFLoader(\"data/resume_with_capg.pdf\")\n",
    "documents = loader.load()\n",
    "for i in documents:\n",
    "    resume+=(i.page_content.strip())\n",
    "    \n",
    "with open('prompts.yaml', 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "    \n",
    "def intro():\n",
    "\n",
    "    print(\"*\"*100)\n",
    "    for i,j in enumerate(data.keys()):\n",
    "        print(f\"{i+1}. {j}\")\n",
    "def inputs():\n",
    "    i=input(\"Enter the number corresponding to the key you want to use: \")\n",
    "    print(\"selected number is \",int(i))\n",
    "    key=list(data.keys())[int(i)-1]\n",
    "    return key\n",
    "\n",
    "def func(key):\n",
    "    input_variables=list(data[key][\"inputs\"].keys())\n",
    "    template=data[key][\"prompt\"].format(resume=resume, job_description=job_description,personal_info=personal_info)\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=input_variables,\n",
    "        template=template\n",
    "    )\n",
    "    print(prompt_template,input_variables)\n",
    "    chain=prompt_template | llm\n",
    "    response=chain.invoke(data[key][\"inputs\"]).content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "93da96c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "1. resume_and_job_decription_rewrite\n",
      "2. cold_mail_and_person_info\n",
      "3. cold_mail_no_personal_info\n"
     ]
    }
   ],
   "source": [
    "intro()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0809b6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected number is  2\n"
     ]
    }
   ],
   "source": [
    "x=inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "58369e0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'person_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[119]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mfunc\u001b[39m\u001b[34m(key)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc\u001b[39m(key):\n\u001b[32m     28\u001b[39m     input_variables=\u001b[38;5;28mlist\u001b[39m(data[key][\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m].keys())\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     template=\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_description\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjob_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpersonal_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersonal_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     prompt_template = PromptTemplate(\n\u001b[32m     31\u001b[39m         input_variables=input_variables,\n\u001b[32m     32\u001b[39m         template=template\n\u001b[32m     33\u001b[39m     )\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mprint\u001b[39m(prompt_template,input_variables)\n",
      "\u001b[31mKeyError\u001b[39m: 'person_info'"
     ]
    }
   ],
   "source": [
    "print(func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f322639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "Rewrite the following resume to match the job description provided:\n",
      "\n",
      "Resume: Dinesh\tSagar\n",
      "+91-8121909150\n",
      "\t\n",
      "Mail\n",
      "\t\n",
      "GitHub\n",
      "\t\n",
      "LinkedIn\tProfile\n",
      "Passionate\tData\tScientist\twith\ta\tdrive\tto\ttackle\treal-world\tchallenges\tthrough\tdata\tanalysis\tand\tmachine\tlearning.\n",
      "Committed\tto\textracting\tvalue\tfrom\tcomplex\tdata\tand\tdelivering\tactionable\tinsights\tto\tinform\tbusiness\tdecisions\t\n",
      "and\n",
      "drive\tgrowth.\tEager\tto\tcontinuously\tlearn\tand\timprove\tto\tdeliver\timpactful\tsolutions.\n",
      "Experience\n",
      "Capgemini\n",
      "Consultant\n",
      "FEB\t2025-\tPRESENT\n",
      "Amazon\tDevelopment\tCentre\tIndia\n",
      "Quality\tSpecialist\n",
      "JAN\t2020\t-\tDEC\t2024\n",
      "Implemented\tan\toutlier\tdetection\tprogram\tto\n",
      "enhance\taddress\tdata\tquality,\timproving\tlogistics\n",
      "performance\tfor\tAmazon\tLogistics.\n",
      "Analyzed\tlarge-scale\tdatasets\tusing\tstatistical\n",
      "methods\tto\toptimize\tdelivery\toperations\tand\n",
      "resource\tplanning.\n",
      "Built\ttime\tseries\tmodels\tto\tforecast\tpeak\torder\n",
      "volumes,\tenabling\tproactive\tlogistics\n",
      "management.\n",
      "Developed\tmachine\tlearning\tmodels\tto\tevaluate\n",
      "delivery\tagent\tperformance,\tdriving\toperational\n",
      "efficiency.\n",
      "Created\tinteractive\tdashboards\tfor\treal-time\n",
      "monitoring\tand\tactionable\tinsights.\n",
      "Skills\n",
      "Programming:\n",
      "\tPython,\tSQL\n",
      "Data\tVisualization:\n",
      "\tTableau,\tPower\tBI\n",
      "Statistics\t&\tMath:\n",
      "\tStatistics\tand\tHypothesis\n",
      "Testing,\tNumPy,\tPandas,\tScikit-Learn\n",
      "Machine\tLearning:\n",
      "\tTensorFlow,\tKeras,\n",
      "Streamlit,\tFlask,\tFastAPI\n",
      "Generative\tAI:\n",
      "\tLangChain,\tLangGraph,\tAWS\n",
      "Bedrock,\tAzure\tAI\tFoundry,\tAzure\tMachine\n",
      "Learning,\tAWS\tSagemaker\n",
      "Scaler\tCertifications\n",
      "Python\tLibraries,\tEDA\tFundamentals\n",
      "Supervised\t&\tUnsupervised\tLearning\n",
      "Natural\tLanguage\tProcessing,\tComputer\tVision\n",
      "Projects\n",
      "Generative\tAI\tPowered\tData\tAssistants\n",
      "Medical\tRAG\tagent:\n",
      "\tDeveloped\ta\tmedical\tchatbot\tusing\n",
      "Pinecone\tDB\tfor\tvector\tstorage\tand\tFlask\tfor\treal-time\tquery\n",
      "handling\tto\tprovide\taccurate,\tcontext-driven\tmedical\n",
      "answers.\n",
      "RAG\tAgent\twith\tChromaDB:\n",
      "\tDeveloped\tan\tintelligent\n",
      "recommendation\tsystem\tleveraging\tChromaDB\tfor\treranking\n",
      "and\tcontent\tdiscovery\tbased\ton\tuser\tqueries.\n",
      "CSV\tCommand\tAgent:\n",
      "\tBuilt\tan\tAI-powered\ttool\tenabling\n",
      "natural\tlanguage\tmanipulation\tof\tCSV\tfiles\tand\tSQL\tquery\n",
      "generation,\tsimplifying\tdata\toperations\tfor\tnon-technical\n",
      "users.\n",
      "Named\tEntity\tRecognition\t(NER)\tin\tTweets\n",
      "Using\tLSTM+CRF\tand\tBERT\tModels\n",
      "Developed\ta\trobust\tNamed\tEntity\tRecognition\t(NER)\tsystem\n",
      "for\ttweets\tusing\tLSTM-CRF\tand\tBERT\tmodels.\n",
      "Initialized\tLSTM-CRF\twith\tWord2Vec\tembeddings\tand\tfine-\n",
      "tuned\tBERT\tfor\tentity\tdetection.\n",
      "Executed\tdata\tpreprocessing,\thyperparameter\toptimization,\n",
      "and\tmodel\tevaluation\tto\tboost\taccuracy.\n",
      "Achieved\tprecise\tentity\trecognition\ton\treal-world\ttweet\tdata,\n",
      "ensuring\thigh\tmodel\tperformance.\n",
      "Ninjacart\tComputer\tVision\tProject\n",
      "Developed\ta\tCNN-based\tcomputer\tvision\tsystem\tfor\n",
      "Ninjacart\tto\tidentify\tonions,\tpotatoes,\ttomatoes,\tand\tnoise\tin\n",
      "produce\timages.\n",
      "Leveraged\ttransfer\tlearning\t(VGG,\tResNet)\tand\tdata\n",
      "augmentation,\twith\toptimized\ttraining\tvia\tcallbacks\tand\n",
      "regularization\ttechniques.\n",
      "Achieved\trobust\tand\taccurate\tvegetable\tclassification.\n",
      "Delivery\tTime\tEstimation\tfor\tPorter's\tDelivery\n",
      "Service\n",
      "Performed\tcomprehensive\tdata\tcleaning,\tfeature\n",
      "engineering,\tand\tcategorical\tencoding\n",
      "Designed,\ttrained,\tand\toptimized\ta\tneural\tnetwork\tmodel\n",
      "using\tTensorFlow\tand\tKeras\n",
      "Delivered\taccurate\tdelivery\ttime\tpredictions,\tenhancing\n",
      "service\tquality\tand\toperational\tefficiency\n",
      "AdEase\tWiki\tPage\tView\tForecasting\n",
      "Forecasted\tWikipedia\tpage\tviews\tto\toptimize\tad\tplacement\n",
      "for\tAdEase\tclients,\tconsidering\tregional\tand\tlinguistic\n",
      "variations.\n",
      "Applied\tARIMA,\tSARIMAX,\tand\tProphet\ttime\tseries\tmodels,\n",
      "incorporating\texogenous\tcampaign\tdata\tfor\tenhanced\n",
      "accuracy.\n",
      "Improved\tad\tplacement\tstrategies\tbased\ton\tpredicted\tpage\n",
      "view\ttrends,\tenabling\tbetter\tROI\tand\ttargeted\tadvertising\n",
      "campaigns\tfor\tdiverse\tregions.Education\n",
      "Scaler\n",
      "Data\tScience\tand\tMachine\tLearning\n",
      "2024\n",
      "Chaitanya\tBharathi\tInstitute\tof\n",
      "Technology\n",
      "B.E(Mechanical)\n",
      "2019\n",
      "ZEE\tRecommendation\tSystem\n",
      "Implemented\ta\tmovie\trecommender\tsystem\tfor\tpersonalized\n",
      "movie\tsuggestions.\n",
      "Utilized\tuser-user\tand\titem-item\tsimilarity\twith\tCosine\tand\n",
      "Pearson\tmethods.\n",
      "Built\tcollaborative\tfiltering\tand\tmatrix\tfactorization\tmodels\n",
      "for\trecommendations.\n",
      "Enhanced\tuser\texperience\tthrough\tdata-driven\tmovie\n",
      "suggestions\n",
      "Graduate\tAdmissions\tPrediction\n",
      "Analyzed\tgraduate\tadmissions\tdata,\tconstructed\tprecise\n",
      "linear\tregression\tmodels\tin\tPython,\tand\tpresented\tactionable\n",
      "insights\tto\tenhance\tstudent\tsuccess\tfor\tJamboree.\n",
      "Created\tLinear\tregression\tmodel\tand\timplemented\tRidge\tand\n",
      "Lasso\tregularizations\tand\tevaluated\tmodel\tmetrics\tusing\n",
      "sklearn\tstats\tlibrary.\tIdentified\tsignificant\tpredictors\t(e.g.,\n",
      "GRE\tscores,\tGPA)\tfor\tgraduate\tadmissions.\n",
      "Developed\taccurate\tlinear\tregression\tmodels\twith\tR2\tscore\n",
      "exceeding\t0.8.\n",
      "Delivered\tinsights\tand\trecommendations\tfor\timproving\n",
      "application\tprofiles.\n",
      "LoanTap\tCreditworthiness\tModel\n",
      "Developed\ta\tLogistic\tRegression\tmodel\tfor\tLoanTap,\n",
      "analyzed\tprecision\tvs.\trecall\ttradeoffs,\tand\tprovided\n",
      "actionable\tinsights\tfor\tenhanced\tloan\tdecisions.\n",
      "Created\tseveral\tflags\tand\tindicators\tbased\ton\tthe\tgiven\n",
      "features\tand\tapplied\ta\tlogistic\tregression\tmodel\tto\tgenerate\n",
      "classification\treport,\tROC\tAUC\tcurve,\tprecision-recall\tcurve.\n",
      "Revealed\tkey\trelationships\tbetween\tloan\tstatus\tand\n",
      "borrower\tattributes.\n",
      "Achieved\thigh\tAUC\tscore,\tindicating\tstrong\tmodel\n",
      "performance.\n",
      "Provided\tinsights\tinto\tsignificant\tpredictors\tof\tloan\tdefaults,\n",
      "leading\tto\timproved\tcreditworthiness\tassessment.\n",
      "\n",
      "Job Description: Summary\n",
      "\n",
      " Position Summary \n",
      "\n",
      "Job Role: Data Scientist Consultant\n",
      "\n",
      "New Business Innovation anticipates how technology will shape the future and begins building future capabilities and practices today. NBI drives the Ideation, Incubation and scale of hybrid businesses and tech enabled offerings at prioritized offering portfolio and industry interactions.\n",
      "\n",
      "It drives cultural and capability transformation from solely services – based businesses to hybrid businesses. While others bet on the future, NBI builds it with you. NBI partners with the network such as converge, Small factory, True Serve, Cortex AI to build hybrid businesses, enterprise platforms and incubate emerging practices to future proof business and help clients get there, first.\n",
      "\n",
      "NBI encompasses many teams—dreamers, designers, builders—and partners with the business to bring a unique POV to deliver services and products for clients.\n",
      "\n",
      "Work you’ll do\n",
      "\n",
      "Key job responsibilities include but are not limited to…\n",
      "\n",
      "The Commercial Insights Senior Data Scientist will work closely with the Commercial Insights India Lead to deliver innovative and transformative data science solutions. The Data Scientist will be consistently challenged— leveraging both existing strengths and developing new skills. Soutions will range from natural language processing to time series algorithms to more straightforward regression/classification modeling .\n",
      "\n",
      "The Data Scientist will be responsible for understanding the business requirements and making sure the technical environment and solution fulfill those business requirements in the most efficient way. In order to do this, he/she will work with  and mentor fellow Commercial Insights Data Scientists, designers, IT professionals, software developers, and his/her own network. Due to the nature of the sales process, work take place in a constantly evolving environment, so agility and flexibility will be critical.\n",
      "\n",
      "Specific responsibilities include:\n",
      "\n",
      " Develop a deep understanding of the Consulting sales process \n",
      " Interrogate the data stored in the MS Azure data science lab and other secure locations \n",
      " Collect and document business requirements \n",
      " Develop industry-leading designs \n",
      " Develop the solution—either programming directly, or serving as an advisor to more junior programmers \n",
      " Test the solution \n",
      " Coordinate industrialization of the solution so that it can be used throughout Deloitte Consulting US \n",
      " Participate in a network of data scientists across Deloitte departments to ensure a culture of inclusivity and innovation \n",
      " Commit to continuous improvement and learning—both personally and in support of team members \n",
      " Provide honest and open transparency into work successes and challenges \n",
      "\n",
      "The Team\n",
      "\n",
      " Partner responsible for informing and accelerating your hybrid business with market-led, offering perspective to incubate differentiated client opportunities from possibility to scaled profitability. \n",
      " Steward of Deloitte’s investment in Hybrid Businesses that drive new and sustained value for Deloitte stakeholders. \n",
      "\n",
      "Qualifications And Experience\n",
      "\n",
      "Required:\n",
      "\n",
      " Strong verbal and written English communication skills \n",
      " Deep curiosity about the Consulting sales process \n",
      " Proactive, self-motivated and demonstrated ability to work independently with minimal guidance \n",
      " Strong interpersonal skills \n",
      " Knowledge of current data science techniques and passion for staying current \n",
      " Familiarity with MS Azure and Data Bricks \n",
      " Familiarity with Tableau \n",
      " Data munging skills using R and Python \n",
      " Strong data science skills \n",
      " Deep insights into statistical modeling and simulation tools Python \n",
      " Good understanding and implementation of complex data science algorithms \n",
      " Experience with Big Data execution using PySpark \n",
      " Strong knowledge of statistics \n",
      " Experience with Machine Learning and deployment and maintenance of models \n",
      "\n",
      "Our purpose\n",
      "\n",
      "Deloitte’s purpose is to make an impact that matters for our people, clients, and communities. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. Our purpose comes through in our work with clients that enables impact and value in their organizations, as well as through our own investments, commitments, and actions across areas that help drive positive outcomes for our communities.\n",
      "\n",
      "Our people and culture\n",
      "\n",
      "Our inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our clients' most complex challenges. This makes Deloitte one of the most rewarding places to work.\n",
      "\n",
      "Professional development\n",
      "\n",
      "At Deloitte, professionals have the opportunity to work with some of the best and discover what works best for them. Here, we prioritize professional growth, offering diverse learning and networking opportunities to help accelerate careers and enhance leadership skills. Our state-of-the-art DU: The Leadership Center in India, located in Hyderabad, represents a tangible symbol of our commitment to the holistic growth and development of our people. Explore DU: The Leadership Center in India .\n",
      "\n",
      "Benefits To Help You Thrive\n",
      "\n",
      "At Deloitte, we know that great people make a great organization. Our comprehensive rewards program helps us deliver a distinctly Deloitte experience that helps that empowers our professionals to thrive mentally, physically, and financially—and live their purpose. To support our professionals and their loved ones, we offer a broad range of benefits. Eligibility requirements may be based on role, tenure, type of employment and/ or other criteria. Learn more about what working at Deloitte can mean for you.\n",
      "\n",
      "Recruiting tips\n",
      "\n",
      "From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters.\n",
      "\n",
      "\n",
      "Instructions:\n",
      "1) Use the available experience, projects, and skills to rewrite the resume.\n",
      "2) Don't Halucinate.\n",
      "3) Don't use any external data but only the resume and job description.\n",
      "4) Don't mention any comments and preamble in the response.\n",
      "\"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[list(data.keys())[0]][\"prompt\"].)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b850fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfa791e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "creating a tool for llm that takes user input and uses the func function to get the response\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def get_response(resume: str, job_description: str) -> str: \n",
    "    \"\"\"\n",
    "    Use this tool to get a response based on the resume and job description.\n",
    "    \"\"\"\n",
    "    #\n",
    "    response = func(key)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dedd51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Binding the tool to the LLM\"\"\"   \n",
    " \n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"get_response\",\n",
    "        func=get_response,\n",
    "        description=\"Use this tool to get a response based on the resume and job description.\"\n",
    "    )\n",
    "]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28feb0db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkey\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/github_analysis/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5431\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5429\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5430\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/github_analysis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:379\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    368\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     **kwargs: Any,\n\u001b[32m    374\u001b[39m ) -> BaseMessage:\n\u001b[32m    375\u001b[39m     config = ensure_config(config)\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    377\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    378\u001b[39m         \u001b[38;5;28mself\u001b[39m.generate_prompt(\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m             [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[32m    380\u001b[39m             stop=stop,\n\u001b[32m    381\u001b[39m             callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    382\u001b[39m             tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    383\u001b[39m             metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    384\u001b[39m             run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    385\u001b[39m             run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    386\u001b[39m             **kwargs,\n\u001b[32m    387\u001b[39m         ).generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    388\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/github_analysis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:364\u001b[39m, in \u001b[36mBaseChatModel._convert_input\u001b[39m\u001b[34m(self, model_input)\u001b[39m\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages=convert_to_messages(model_input))\n\u001b[32m    360\u001b[39m msg = (\n\u001b[32m    361\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    363\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages."
     ]
    }
   ],
   "source": [
    "llm_with_tools.invoke({\"key\":\"1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71163108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b075c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eaf4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a7c01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9e94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28657b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5b2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087c605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d9da51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53a3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2746d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
