{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import List, TypedDict, Annotated\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "\"\"\"\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.graph import Graph, Node, StartNode, StopNode\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\"\"\"\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.environ[\"groq\"]\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0468482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c26187d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Taj Mahal is located in Agra, a city in the Indian state of Uttar Pradesh. It is situated on the southern bank of the Yamuna River, approximately 230 kilometers (143 miles) south of New Delhi, the capital city of India.\\n\\nThe exact address of the Taj Mahal is:\\n\\nTaj Mahal, Dharmapuri, Forest Colony, Tajganj, Agra, Uttar Pradesh 282001, India\\n\\nIt is one of the most famous and iconic monuments in the world, and a popular tourist destination, attracting millions of visitors each year.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"where is taj mahal?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05468958",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume=\"\"\n",
    "with open('data/job_description.txt', 'r') as file:\n",
    "    job_description=file.read()\n",
    "loader = PyPDFLoader(\"data/resume_with_capg.pdf\")\n",
    "documents = loader.load()\n",
    "for i in documents:\n",
    "    resume+=(i.page_content.strip())\n",
    "    \n",
    "with open('prompts.yaml', 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "    \n",
    "def intro():\n",
    "\n",
    "    print(\"*\"*100)\n",
    "    for i,j in enumerate(data.keys()):\n",
    "        print(f\"{i+1}. {j}\")\n",
    "def inputs():\n",
    "    i=input(\"Enter the number corresponding to the key you want to use: \")\n",
    "    print(\"selected number is \",int(i))\n",
    "    key=list(data.keys())[int(i)-1]\n",
    "    return key\n",
    "\n",
    "def func(key):\n",
    "    input_variables=list(data[key][\"inputs\"].keys())\n",
    "    template=data[key][\"prompt\"]\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=input_variables,\n",
    "        template=template\n",
    "    )\n",
    "    print(prompt_template,input_variables)\n",
    "    chain=prompt_template | llm\n",
    "    response=chain.invoke(data[key][\"inputs\"]).content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "93da96c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "1. resume_and_job_decription_rewrite\n",
      "2. cold_mail_and_person_info\n",
      "3. cold_mail_no_personal_info\n"
     ]
    }
   ],
   "source": [
    "intro()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0809b6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected number is  1\n"
     ]
    }
   ],
   "source": [
    "x=inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "58369e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['job_description', 'resume'] input_types={} partial_variables={} template='\"\"\"\\nRewrite the following resume to match the job description provided:\\n\\nResume: {resume}\\n\\nJob Description: {job_description}\\n\\nInstructions:\\n1) Use the available experience, projects, and skills to rewrite the resume.\\n2) Don\\'t Halucinate.\\n3) Don\\'t use any external data but only the resume and job description.\\n4) Don\\'t mention any comments and preamble in the response.\\n\"\"\"\\n' ['resume', 'job_description']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't see a resume or job description provided. Please provide the necessary information so I can assist you with rewriting the resume to match the job description.\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f322639e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{a}\u001b[39;00m\u001b[33m +\u001b[39m\u001b[38;5;132;01m{b}\u001b[39;00m\u001b[33m=sum\u001b[39m\u001b[33m\"\u001b[39m.format({\u001b[43ma\u001b[49m:\u001b[32m4\u001b[39m,b:\u001b[32m5\u001b[39m})\n",
      "\u001b[31mNameError\u001b[39m: name 'a' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b850fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfa791e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "creating a tool for llm that takes user input and uses the func function to get the response\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def get_response(resume: str, job_description: str) -> str: \n",
    "    \"\"\"\n",
    "    Use this tool to get a response based on the resume and job description.\n",
    "    \"\"\"\n",
    "    #\n",
    "    response = func(key)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dedd51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Binding the tool to the LLM\"\"\"   \n",
    " \n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"get_response\",\n",
    "        func=get_response,\n",
    "        description=\"Use this tool to get a response based on the resume and job description.\"\n",
    "    )\n",
    "]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28feb0db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkey\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/github_analysis/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5431\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5429\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5430\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/github_analysis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:379\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    368\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     **kwargs: Any,\n\u001b[32m    374\u001b[39m ) -> BaseMessage:\n\u001b[32m    375\u001b[39m     config = ensure_config(config)\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    377\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    378\u001b[39m         \u001b[38;5;28mself\u001b[39m.generate_prompt(\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m             [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[32m    380\u001b[39m             stop=stop,\n\u001b[32m    381\u001b[39m             callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    382\u001b[39m             tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    383\u001b[39m             metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    384\u001b[39m             run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    385\u001b[39m             run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    386\u001b[39m             **kwargs,\n\u001b[32m    387\u001b[39m         ).generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    388\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/github_analysis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:364\u001b[39m, in \u001b[36mBaseChatModel._convert_input\u001b[39m\u001b[34m(self, model_input)\u001b[39m\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages=convert_to_messages(model_input))\n\u001b[32m    360\u001b[39m msg = (\n\u001b[32m    361\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    363\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages."
     ]
    }
   ],
   "source": [
    "llm_with_tools.invoke({\"key\":\"1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71163108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b075c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eaf4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a7c01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9e94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28657b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5b2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087c605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d9da51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53a3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2746d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
